services:
  frontend:
    build: ./frontend
    container_name: frontend_app_v2
    networks:
      - airflow-net-v2
    ports:
      - "8003:8003"
    volumes:
      - ./frontend:/app
  django:
    build: ./backend
    container_name: django_app_v2
    networks:
      - airflow-net-v2
    depends_on:
      - postgres
    ports:
      - "8001:8000"
    environment:
      - DJANGO_SETTINGS_MODULE=pandemics_project.settings
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY:-your-secret-key}
      - DJANGO_DEBUG=${DJANGO_DEBUG:-True}
      - DJANGO_ALLOWED_HOSTS=${DJANGO_ALLOWED_HOSTS:-127.0.0.1,localhost}
      - POSTGRES_DB=${POSTGRES_DB:-pandemies}
      - POSTGRES_USER=${POSTGRES_USER:-user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-guigui}
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
    volumes:
      - ./backend:/django_api
      - ml_models_v2:/django_api/pandemics_app/ml/models
    # ðŸ”§ OPTIMISATIONS POUR ML
    deploy:
      resources:
        limits:
          memory: 4G          # Augmente la mÃ©moire
          cpus: '2.0'         # Augmente les CPU
        reservations:
          memory: 2G
          cpus: '1.0'
    # Configuration pour Ã©viter les timeouts
    stop_grace_period: 30s
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health-check/"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: >
      sh -c "python manage.py migrate &&
             python manage.py runserver 0.0.0.0:8000"

  postgres:
    image: postgres:13
    container_name: postgres_db_v2
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: guigui
      POSTGRES_DB: pandemies
      # ðŸ”§ OPTIMISATIONS POSTGRES
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
    networks:
      - airflow-net-v2
    ports:
      - "5433:5432"
    volumes:
      - postgres_data_v2:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    # ðŸ”§ OPTIMISATIONS POUR BASE DE DONNÃ‰ES
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  airflow-webserver:
    image: apache/airflow:2.7.2
    container_name: airflow_webserver_v2
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://user:guigui@postgres/pandemies
      AIRFLOW__CORE__FERNET_KEY: tym5nXoBS3cJ9UAerkjX6Ffebr5AqU3YjQWf31JGKfA=
      AIRFLOW__WEBSERVER__WORKER_REFRESH_BATCH_SIZE: 10
      AIRFLOW__WEBSERVER__SECRET_KEY: 113QWMWwTtueNy-ca6BUFeOF5mRTBoQ6Rb7elifprXY
    networks:
      - airflow-net-v2
    depends_on:
      - postgres
    ports:
      - "8081:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
    command: >
      bash -c "airflow db upgrade &&
               airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || true &&
               airflow webserver"

  airflow-scheduler:
    image: apache/airflow:2.7.2
    container_name: airflow_scheduler_v2
    depends_on:
      - postgres
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://user:guigui@postgres/pandemies
      AIRFLOW__CORE__FERNET_KEY: tym5nXoBS3cJ9UAerkjX6Ffebr5AqU3YjQWf31JGKfA=
      AIRFLOW__WEBSERVER__SECRET_KEY: 113QWMWwTtueNy-ca6BUFeOF5mRTBoQ6Rb7elifprXY
    networks:
      - airflow-net-v2
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
    command: "airflow scheduler"

  metabase:
    image: metabase/metabase:latest
    container_name: metabase_v2
    environment:
      - MB_DB_FILE=/metabase-data/metabase.db
    networks:
      - airflow-net-v2
    ports:
      - "3001:3000"
    volumes:
      - metabase_data_v2:/metabase-data

networks:
  airflow-net-v2:

volumes:
  postgres_data_v2:
  metabase_data_v2:
  ml_models_v2: